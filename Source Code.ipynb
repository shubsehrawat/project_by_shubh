{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv(r\"C:\\Users\\shubham\\Desktop\\HackerEarth\\hm_train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\shubham\\Desktop\\HackerEarth\\hm_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hmid                 0.0\n",
       "reflection_period    0.0\n",
       "cleaned_hm           0.0\n",
       "num_sentence         0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Missing value analysis in training data\n",
    "train_miss=train.isna().sum()\n",
    "train_miss/len(train)\n",
    "#No missing values in the train data\n",
    "\n",
    "#Missing value analysis in test data\n",
    "test_miss=test.isna().sum()\n",
    "test_miss/len(test)\n",
    "#No missing data in the test data either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean data\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "def cleanData(text, lowercase = False, remove_stops = False, stemming = False):\n",
    "    txt = str(text)\n",
    "    txt = re.sub(r'[^A-Za-z0-9\\s]',r'',txt)\n",
    "    txt = re.sub(r'\\n',r' ',txt)\n",
    "    \n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "        \n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    \n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_reflection(per):\n",
    "    if per==\"24h\":\n",
    "        return 24\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pred_cat(cat):\n",
    "    if cat==\"affection\":\n",
    "        return 0\n",
    "    elif cat==\"exercise\":\n",
    "        return 1\n",
    "    elif cat==\"bonding\":\n",
    "        return 2\n",
    "    elif cat==\"achievement\":\n",
    "        return 3\n",
    "    elif cat==\"enjoy_the_moment\":\n",
    "        return 4\n",
    "    elif cat==\"leisure\":\n",
    "        return 5\n",
    "    elif cat==\"nature\":\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the data for cleaning\n",
    "test['predicted_category'] = np.nan\n",
    "merged_data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning and Refining\n",
    "merged_data['cleaned_hm'] = merged_data['cleaned_hm'].map(lambda x: cleanData(x, lowercase=True, remove_stops=True, stemming=True))\n",
    "merged_data['reflection_period']=merged_data['reflection_period'].map(convert_reflection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[\"predicted_category\"]=merged_data[\"predicted_category\"].map(convert_pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Count vectorizer\n",
    "countvec = CountVectorizer(analyzer='word', ngram_range = (1,1), min_df=150, max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features\n",
    "bagofwords = countvec.fit_transform(merged_data['cleaned_hm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['reflection_period','num_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for features\n",
    "bow_df = pd.DataFrame(bagofwords.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set column names\n",
    "bow_df.columns = ['col'+ str(x) for x in bow_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.concat([merged_data[cols], bow_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the test and train data\n",
    "train_data_final=data_final[:len(train)]\n",
    "test_data_final=data_final[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=merged_data['predicted_category'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    2.0\n",
       "4    0.0\n",
       "Name: predicted_category, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85356758 0.84874855 0.84482759 0.83884606 0.83293259]\n"
     ]
    }
   ],
   "source": [
    "# Applying Logistic regression\n",
    "\n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(train_data_final, target)\n",
    "pred_lr=reg.predict(test_data_final)\n",
    "print(cross_val_score(reg, train_data_final, target, cv=5, scoring=make_scorer(accuracy_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(cat):\n",
    "    if cat==0:\n",
    "        return \"affection\"\n",
    "    elif cat==1:\n",
    "        return \"exercise\"\n",
    "    elif cat==2:\n",
    "        return \"bonding\"\n",
    "    elif cat==3:\n",
    "        return \"achievement\"\n",
    "    elif cat==4:\n",
    "        return \"enjoy_the_moment\"\n",
    "    elif cat==5:\n",
    "        return \"leisure\"\n",
    "    else:\n",
    "        return \"nature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the submission files\n",
    "submission_file = pd.DataFrame({'hmid':test.hmid, 'predicted_category':pred_lr})\n",
    "submission_file['predicted_category'] = submission_file['predicted_category'].map(lambda x: to_labels(x))\n",
    "submission_file = submission_file[['hmid', 'predicted_category']]\n",
    "submission_file.to_csv(r\"C:\\Users\\shubham\\Desktop\\HackerEarth\\submission_file_lr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88305</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88306</td>\n",
       "      <td>achievement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88307</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88308</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88309</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid predicted_category\n",
       "0  88305            bonding\n",
       "1  88306        achievement\n",
       "2  88307          affection\n",
       "3  88308            bonding\n",
       "4  88309          affection"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
